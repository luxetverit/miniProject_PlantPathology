{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\nimport torch.optim as optim\n# 시드값 고정\nseed = 42\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-11T07:40:24.043527Z","iopub.execute_input":"2023-01-11T07:40:24.044080Z","iopub.status.idle":"2023-01-11T07:40:24.054013Z","shell.execute_reply.started":"2023-01-11T07:40:24.044025Z","shell.execute_reply":"2023-01-11T07:40:24.052760Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.057080Z","iopub.execute_input":"2023-01-11T07:40:24.057488Z","iopub.status.idle":"2023-01-11T07:40:24.070660Z","shell.execute_reply.started":"2023-01-11T07:40:24.057451Z","shell.execute_reply":"2023-01-11T07:40:24.069538Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')\nfrom sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(train, \n                                test_size=0.1,\n                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n                                random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.073179Z","iopub.execute_input":"2023-01-11T07:40:24.074512Z","iopub.status.idle":"2023-01-11T07:40:24.123915Z","shell.execute_reply.started":"2023-01-11T07:40:24.074476Z","shell.execute_reply":"2023-01-11T07:40:24.122862Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\nimport numpy as np\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None, is_test=False):\n        super().__init__() # 상속받은 Dataset의 __init__() 메서드 호출\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n\n    # 인덱스(idx)에 해당하는 데이터 반환 메서드\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]             # 이미지 ID\n        img_path = self.img_dir + img_id + '.jpg' # 이미지 파일 경로\n        image = cv2.imread(img_path)              # 이미지 파일 읽기\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        # 이미지 변환 \n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        # 테스트 데이터면 이미지 데이터만 반환, 그렇지 않으면 타깃값도 반환 \n        if self.is_test:\n            return image # 테스트용일 때\n        else:\n            # 타깃값 4개 중 가장 큰 값의 인덱스 \n            label = np.argmax(self.df.iloc[idx, 1:5]) \n            return image, label # 훈련/검증용일 때","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.127437Z","iopub.execute_input":"2023-01-11T07:40:24.128607Z","iopub.status.idle":"2023-01-11T07:40:24.142049Z","shell.execute_reply.started":"2023-01-11T07:40:24.128568Z","shell.execute_reply":"2023-01-11T07:40:24.140943Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# 이미지 변환을 위한 모듈\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.144344Z","iopub.execute_input":"2023-01-11T07:40:24.145736Z","iopub.status.idle":"2023-01-11T07:40:24.152701Z","shell.execute_reply.started":"2023-01-11T07:40:24.145698Z","shell.execute_reply":"2023-01-11T07:40:24.151617Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# 훈련 데이터용 변환기\ntransform_train = A.Compose([\n    A.Resize(450, 650),       # 이미지 크기 조절 \n    A.RandomBrightnessContrast(brightness_limit=0.2, # 밝기 대비 조절\n                               contrast_limit=0.2, p=0.3),\n    A.VerticalFlip(p=0.2),    # 상하 대칭 변환\n    A.HorizontalFlip(p=0.5),  # 좌우 대칭 변환 \n    A.ShiftScaleRotate(       # 이동, 스케일링, 회전 변환\n        shift_limit=0.1,\n        scale_limit=0.2,\n        rotate_limit=30, p=0.3),\n    A.OneOf([A.Emboss(p=1),   # 양각화, 날카로움, 블러 효과\n             A.Sharpen(p=1),\n             A.Blur(p=1)], p=0.3),\n    A.PiecewiseAffine(p=0.3), # 어파인 변환 \n    A.Normalize(),            # 정규화 변환 \n    ToTensorV2()              # 텐서로 변환\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.155177Z","iopub.execute_input":"2023-01-11T07:40:24.156839Z","iopub.status.idle":"2023-01-11T07:40:24.168997Z","shell.execute_reply.started":"2023-01-11T07:40:24.156797Z","shell.execute_reply":"2023-01-11T07:40:24.167885Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# 검증 및 테스트 데이터용 변환기\ntransform_test = A.Compose([\n    A.Resize(450, 650), # 이미지 크기 조절 \n    A.Normalize(),      # 정규화 변환\n    ToTensorV2()        # 텐서로 변환\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.171253Z","iopub.execute_input":"2023-01-11T07:40:24.172443Z","iopub.status.idle":"2023-01-11T07:40:24.181293Z","shell.execute_reply.started":"2023-01-11T07:40:24.172404Z","shell.execute_reply":"2023-01-11T07:40:24.180252Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\ndataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.183667Z","iopub.execute_input":"2023-01-11T07:40:24.185069Z","iopub.status.idle":"2023-01-11T07:40:24.192379Z","shell.execute_reply.started":"2023-01-11T07:40:24.185028Z","shell.execute_reply":"2023-01-11T07:40:24.191353Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.194495Z","iopub.execute_input":"2023-01-11T07:40:24.195732Z","iopub.status.idle":"2023-01-11T07:40:24.207243Z","shell.execute_reply.started":"2023-01-11T07:40:24.195694Z","shell.execute_reply":"2023-01-11T07:40:24.206178Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f30a34efc70>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 클래스\n\nbatch_size = 4\n\ntrainloader = DataLoader(dataset_train, batch_size=batch_size, \n                          shuffle=True, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)\nvalidloader = DataLoader(dataset_valid, batch_size=batch_size, \n                          shuffle=False, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.258521Z","iopub.execute_input":"2023-01-11T07:40:24.260214Z","iopub.status.idle":"2023-01-11T07:40:24.268533Z","shell.execute_reply.started":"2023-01-11T07:40:24.260170Z","shell.execute_reply":"2023-01-11T07:40:24.267405Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# !pip install efficientnet-pytorch==0.7.1\n# from efficientnet_pytorch import EfficientNet # EfficientNet 모델\n# 사전 훈련된 efficientnet-b7 모델 불러오기\n# model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4) \n\n# model = model.to(device) # 장비 할당","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:24.271596Z","iopub.execute_input":"2023-01-11T07:40:24.272737Z","iopub.status.idle":"2023-01-11T07:40:24.280655Z","shell.execute_reply.started":"2023-01-11T07:40:24.272700Z","shell.execute_reply":"2023-01-11T07:40:24.279582Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\nfrom torchvision import models\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정\nmodel = models.resnet50(pretrained=True).to(device) # true 옵션으로 사전 학습된 모델을 로드","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:43:23.045349Z","iopub.execute_input":"2023-01-11T07:43:23.045743Z","iopub.status.idle":"2023-01-11T07:43:27.933385Z","shell.execute_reply.started":"2023-01-11T07:43:23.045714Z","shell.execute_reply":"2023-01-11T07:43:27.932395Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/97.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8eee70086f544af9ba853d7a7d71803"}},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\nfrom tqdm import tqdm\n# 손실 함수\ncriterion = nn.CrossEntropyLoss()\n\n# 옵티마이저\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001) # 모델파라미터,러닝레이트, 가중치감쇠\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=7, factor=0.1, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:43:30.510371Z","iopub.execute_input":"2023-01-11T07:43:30.510733Z","iopub.status.idle":"2023-01-11T07:43:30.517802Z","shell.execute_reply.started":"2023-01-11T07:43:30.510704Z","shell.execute_reply":"2023-01-11T07:43:30.516800Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def validation(model, validloader, criterion):\n  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비\n  # 이 최종 예측과 정답을 비교\n  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산\n  valid_accuracy = 0\n  valid_loss = 0\n\n  # 전방향 예측을 구할 때는 gradient가 필요가 없음\n  with torch.no_grad():\n    for images, labels in validloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) 10000/16번을 iterations\n      # 0. Data를 GPU로 보내기\n      images, labels = images.to(device), labels.to(device)\n\n      # 1. 입력데이터 준비\n      # not Flatten!!\n      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28\n      \n      # 2. 전방향(Forward) 예측 \n      logits = model.forward(images) # 점수 반환\n      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측\n      # preds= probs.max(dim=1)[1] \n      correct = (preds == labels).sum()\n\n      accuracy = correct / images.shape[0]\n      loss = criterion(logits, labels) # 16개에 대한 loss\n      \n      valid_accuracy += accuracy\n      valid_loss += loss.item() # tensor 값을 꺼내옴\n    \n\n  return valid_loss, valid_accuracy # validloader 전체 대한 총 loss, 총 accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:43:32.817424Z","iopub.execute_input":"2023-01-11T07:43:32.818207Z","iopub.status.idle":"2023-01-11T07:43:32.829271Z","shell.execute_reply.started":"2023-01-11T07:43:32.818161Z","shell.execute_reply":"2023-01-11T07:43:32.828231Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\n\nwriter  = SummaryWriter()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:43:35.329428Z","iopub.execute_input":"2023-01-11T07:43:35.329855Z","iopub.status.idle":"2023-01-11T07:43:35.343225Z","shell.execute_reply.started":"2023-01-11T07:43:35.329823Z","shell.execute_reply":"2023-01-11T07:43:35.342252Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def train(model, epochs, criterion, optimizer):\n  steps = 0\n  min_loss = 10000\n  max_accuracy = 0\n\n  trigger = 0\n  patience = 4 # for Early stopping\n\n  # 1 에폭(epoch)당 반복수\n  #steps_per_epoch = len(trainset)/batch_size # 2500 iterations\n  steps_per_epoch = len(trainloader) # 2500 iterations\n\n  for epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    for images, labels in tqdm(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비\n      steps += 1\n      # 0. Data를 GPU로 보내기\n      images, labels = images.to(device), labels.to(device)\n\n      # 1. 입력 데이터 준비\n      # not Flatten!!\n      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28\n\n      # 2. 전방향(Forward) 예측 \n      outputs = model.forward(images) # 예측\n      loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환\n\n      # 3. 역방향(Backward) 오차(Gradient) 전파\n      optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해\n      loss.backward()\n\n      # 4. 경사하강법으로 모델 파라미터 업데이트\n      optimizer.step() # W <- W -lr*Gradient\n\n      train_loss += loss.item()\n      if (steps % steps_per_epoch) == 0: # step : 2500, .... (epoch 마다)\n        model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정\n        valid_loss, valid_accuracy = validation(model, validloader, criterion)\n\n        # tensorboad 시각화를 위한 로그 이벤트 등록\n        writer.add_scalar(\"Loss/train\", train_loss/len(trainloader), epoch)\n        writer.add_scalar(\"Loss/valid\", valid_loss/len(validloader), epoch)\n        writer.add_scalars(\"Loss/train and valid\",\n                          {'train' : train_loss/len(trainloader),\n                          'valid' : valid_loss/len(validloader)}, epoch)\n        \n        writer.add_scalar(\"Valid Accuracy\", valid_accuracy/len(validloader), epoch)\n\n\n        print('Epoch : {}/{}.....'.format(epoch+1, epochs),\n              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),\n              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),\n              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))\n        \n        # Best model 저장\n        # option 1\n        # if valid_loss < min_loss:\n        #   min_loss = valid_loss\n        #   torch.save(model.state_dict(), 'best_checkpoint.pth')\n\n        # option 2\n        if valid_accuracy > max_accuracy: \n          max_accuracy = valid_accuracy\n          torch.save(model.state_dict(), 'best_checkpoint.pth')\n\n        # Early Stopping (조기 종료)\n        if valid_loss > min_loss:\n          trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가\n          print('trigger : ', trigger )\n          if trigger > patience:\n            print('Early Stopping!!!')\n            print('Traning step is finished!!')\n            writer.flush()  \n            return   \n        else:\n          trigger = 0\n          min_loss = valid_loss\n\n\n        train_loss = 0\n        model.train()\n\n        # Learning Rate Scheduler\n        scheduler.step(valid_loss)\n\n  writer.flush()      ","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:44:12.917275Z","iopub.execute_input":"2023-01-11T07:44:12.917676Z","iopub.status.idle":"2023-01-11T07:44:12.932220Z","shell.execute_reply.started":"2023-01-11T07:44:12.917643Z","shell.execute_reply":"2023-01-11T07:44:12.930956Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"epochs=15\ntrain(model, epochs, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:44:15.217656Z","iopub.execute_input":"2023-01-11T07:44:15.218301Z","iopub.status.idle":"2023-01-11T08:35:13.166407Z","shell.execute_reply.started":"2023-01-11T07:44:15.218263Z","shell.execute_reply":"2023-01-11T08:35:13.165177Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"100%|█████████▉| 409/410 [04:10<00:00,  2.32it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch : 1/15..... Train Loss : 0.703 Valid Loss : 0.222 Valid Accuracy : 0.913\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [04:19<00:00,  1.58it/s]\n100%|█████████▉| 409/410 [04:01<00:00,  1.74it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch : 2/15..... Train Loss : 0.423 Valid Loss : 0.231 Valid Accuracy : 0.935\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [04:10<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"trigger :  1\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 409/410 [03:57<00:00,  2.54it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch : 3/15..... Train Loss : 0.350 Valid Loss : 0.198 Valid Accuracy : 0.946\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [04:07<00:00,  1.66it/s]\n100%|██████████| 410/410 [04:16<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 4/15..... Train Loss : 0.312 Valid Loss : 0.189 Valid Accuracy : 0.935\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 409/410 [04:09<00:00,  2.07it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch : 5/15..... Train Loss : 0.250 Valid Loss : 0.167 Valid Accuracy : 0.951\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [04:18<00:00,  1.59it/s]\n100%|██████████| 410/410 [04:17<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 6/15..... Train Loss : 0.217 Valid Loss : 0.213 Valid Accuracy : 0.940\ntrigger :  1\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 409/410 [04:01<00:00,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch : 7/15..... Train Loss : 0.202 Valid Loss : 0.155 Valid Accuracy : 0.962\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [04:10<00:00,  1.64it/s]\n100%|██████████| 410/410 [04:10<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 8/15..... Train Loss : 0.195 Valid Loss : 0.244 Valid Accuracy : 0.935\ntrigger :  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [04:15<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 9/15..... Train Loss : 0.175 Valid Loss : 0.164 Valid Accuracy : 0.962\ntrigger :  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [04:15<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 10/15..... Train Loss : 0.166 Valid Loss : 0.207 Valid Accuracy : 0.940\ntrigger :  3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [04:14<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 11/15..... Train Loss : 0.173 Valid Loss : 0.202 Valid Accuracy : 0.951\ntrigger :  4\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 409/410 [04:20<00:00,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch : 12/15..... Train Loss : 0.147 Valid Loss : 0.158 Valid Accuracy : 0.957\ntrigger :  5\nEarly Stopping!!!\nTraning step is finished!!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"%load_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2023-01-11T08:35:17.258530Z","iopub.execute_input":"2023-01-11T08:35:17.258950Z","iopub.status.idle":"2023-01-11T08:35:17.265497Z","shell.execute_reply.started":"2023-01-11T08:35:17.258912Z","shell.execute_reply":"2023-01-11T08:35:17.264489Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n","output_type":"stream"}]},{"cell_type":"code","source":"%tensorboard --logdir=runs","metadata":{"execution":{"iopub.status.busy":"2023-01-11T08:35:49.060631Z","iopub.execute_input":"2023-01-11T08:35:49.061040Z","iopub.status.idle":"2023-01-11T08:35:49.074229Z","shell.execute_reply.started":"2023-01-11T08:35:49.060986Z","shell.execute_reply":"2023-01-11T08:35:49.073035Z"},"trusted":true},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":"Reusing TensorBoard on port 6006 (pid 4370), started 0:00:27 ago. (Use '!kill 4370' to kill it.)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-bdd640fb06671ad1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-bdd640fb06671ad1\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}]},{"cell_type":"code","source":"# 테스트 데이터 원본 데이터셋 및 데이터 로더\ndataset_test = ImageDataset(test, img_dir=img_dir, \n                            transform=transform_test, is_test=True)\nloader_test = DataLoader(dataset_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)\n\n# TTA용 데이터셋 및 데이터 로더\ndataset_TTA = ImageDataset(test, img_dir=img_dir, \n                           transform=transform_train, is_test=True)\nloader_TTA = DataLoader(dataset_TTA, batch_size=batch_size, \n                        shuffle=False, worker_init_fn=seed_worker,\n                        generator=g, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:38.545790Z","iopub.status.idle":"2023-01-11T07:40:38.546362Z","shell.execute_reply.started":"2023-01-11T07:40:38.546048Z","shell.execute_reply":"2023-01-11T07:40:38.546092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_tta = submission.copy() \n\nsubmission_tta[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_tta","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:38.548431Z","iopub.status.idle":"2023-01-11T07:40:38.548943Z","shell.execute_reply.started":"2023-01-11T07:40:38.548690Z","shell.execute_reply":"2023-01-11T07:40:38.548717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_test.to_csv('submission_test.csv', index=False)\nsubmission_tta.to_csv('submission_tta.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:38.551214Z","iopub.status.idle":"2023-01-11T07:40:38.551732Z","shell.execute_reply.started":"2023-01-11T07:40:38.551481Z","shell.execute_reply":"2023-01-11T07:40:38.551508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_label_smoothing(df, target, alpha, threshold):\n    # 타깃값 복사\n    df_target = df[target].copy()\n    k = len(target) # 타깃값 개수\n\n    for idx, row in df_target.iterrows():\n        if (row > threshold).any():         # 임계값을 넘는 타깃값인지 여부 판단\n            row = (1 - alpha)*row + alpha/k # 레이블 스무딩 적용  \n            df_target.iloc[idx] = row       # 레이블 스무딩을 적용한 값으로 변환\n    return df_target # 레이블 스무딩을 적용한 타깃값 반환","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:38.553848Z","iopub.status.idle":"2023-01-11T07:40:38.554344Z","shell.execute_reply.started":"2023-01-11T07:40:38.554095Z","shell.execute_reply":"2023-01-11T07:40:38.554131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = 0.001 # 레이블 스무딩 강도\nthreshold = 0.999 # 레이블 스무딩을 적용할 임계값\n\n# 레이블 스무딩을 적용하기 위해 DataFrame 복사\nsubmission_test_ls = submission_test.copy()\nsubmission_tta_ls = submission_tta.copy()\n\ntarget = ['healthy', 'multiple_diseases', 'rust', 'scab'] # 타깃값 열 이름\n\n# 레이블 스무딩 적용\nsubmission_test_ls[target] = apply_label_smoothing(submission_test_ls, target, \n                                                   alpha, threshold)\nsubmission_tta_ls[target] = apply_label_smoothing(submission_tta_ls, target, \n                                                  alpha, threshold)\n\nsubmission_test_ls.to_csv('submission_test_ls.csv', index=False)\nsubmission_tta_ls.to_csv('submission_tta_ls.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T07:40:38.556648Z","iopub.status.idle":"2023-01-11T07:40:38.557139Z","shell.execute_reply.started":"2023-01-11T07:40:38.556875Z","shell.execute_reply":"2023-01-11T07:40:38.556897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
