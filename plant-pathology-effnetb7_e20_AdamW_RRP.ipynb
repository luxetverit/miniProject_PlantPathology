{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:49.578161Z",
     "iopub.status.busy": "2022-08-29T21:21:49.577029Z",
     "iopub.status.idle": "2022-08-29T21:21:52.785039Z",
     "shell.execute_reply": "2022-08-29T21:21:52.784134Z",
     "shell.execute_reply.started": "2022-08-29T21:21:49.577366Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:52.786908Z",
     "iopub.status.busy": "2022-08-29T21:21:52.786544Z",
     "iopub.status.idle": "2022-08-29T21:21:52.81976Z",
     "shell.execute_reply": "2022-08-29T21:21:52.818578Z",
     "shell.execute_reply.started": "2022-08-29T21:21:52.786871Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = './input/plant-pathology-2020-fgvc7/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv')\n",
    "test = pd.read_csv(data_path + 'test.csv')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:52.82162Z",
     "iopub.status.busy": "2022-08-29T21:21:52.821288Z",
     "iopub.status.idle": "2022-08-29T21:21:52.829992Z",
     "shell.execute_reply": "2022-08-29T21:21:52.82899Z",
     "shell.execute_reply.started": "2022-08-29T21:21:52.821587Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:52.833635Z",
     "iopub.status.busy": "2022-08-29T21:21:52.832904Z",
     "iopub.status.idle": "2022-08-29T21:21:52.851763Z",
     "shell.execute_reply": "2022-08-29T21:21:52.850936Z",
     "shell.execute_reply.started": "2022-08-29T21:21:52.833599Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:52.855087Z",
     "iopub.status.busy": "2022-08-29T21:21:52.854482Z",
     "iopub.status.idle": "2022-08-29T21:21:52.864872Z",
     "shell.execute_reply": "2022-08-29T21:21:52.863974Z",
     "shell.execute_reply.started": "2022-08-29T21:21:52.855053Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:52.867015Z",
     "iopub.status.busy": "2022-08-29T21:21:52.866009Z",
     "iopub.status.idle": "2022-08-29T21:21:52.880819Z",
     "shell.execute_reply": "2022-08-29T21:21:52.879871Z",
     "shell.execute_reply.started": "2022-08-29T21:21:52.866981Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2.2 데이터 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃값 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:52.882744Z",
     "iopub.status.busy": "2022-08-29T21:21:52.882205Z",
     "iopub.status.idle": "2022-08-29T21:21:52.897626Z",
     "shell.execute_reply": "2022-08-29T21:21:52.896671Z",
     "shell.execute_reply.started": "2022-08-29T21:21:52.882685Z"
    }
   },
   "outputs": [],
   "source": [
    "healthy = train.loc[train['healthy']==1]\n",
    "multiple_diseases = train.loc[train['multiple_diseases'] == 1]\n",
    "rust = train.loc[train['rust']==1]\n",
    "scab = train.loc[train['scab']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:52.900068Z",
     "iopub.status.busy": "2022-08-29T21:21:52.899358Z",
     "iopub.status.idle": "2022-08-29T21:21:52.914778Z",
     "shell.execute_reply": "2022-08-29T21:21:52.913923Z",
     "shell.execute_reply.started": "2022-08-29T21:21:52.900034Z"
    }
   },
   "outputs": [],
   "source": [
    "scab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:52.916964Z",
     "iopub.status.busy": "2022-08-29T21:21:52.916178Z",
     "iopub.status.idle": "2022-08-29T21:21:52.927503Z",
     "shell.execute_reply": "2022-08-29T21:21:52.926537Z",
     "shell.execute_reply.started": "2022-08-29T21:21:52.916925Z"
    }
   },
   "outputs": [],
   "source": [
    "healthy.shape, multiple_diseases.shape, rust.shape, scab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:52.932433Z",
     "iopub.status.busy": "2022-08-29T21:21:52.931496Z",
     "iopub.status.idle": "2022-08-29T21:21:53.105091Z",
     "shell.execute_reply": "2022-08-29T21:21:53.10405Z",
     "shell.execute_reply.started": "2022-08-29T21:21:52.932399Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.rc('font', size=15)\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "label = ['healthy', 'multiple diseases', 'rust', 'scab']\n",
    "plt.pie([len(healthy), len(multiple_diseases), len(rust), len(scab)],\n",
    "        labels=label,\n",
    "        autopct='%.1f%%');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:53.107535Z",
     "iopub.status.busy": "2022-08-29T21:21:53.106894Z",
     "iopub.status.idle": "2022-08-29T21:21:53.282856Z",
     "shell.execute_reply": "2022-08-29T21:21:53.281901Z",
     "shell.execute_reply.started": "2022-08-29T21:21:53.1075Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "\n",
    "def show_image(img_ids, rows=2, cols=3):\n",
    "    assert len(img_ids) <= rows * cols # 이미지가 행/열 개수보다 많으면 오류 발생\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    grid = gridspec.GridSpec(rows, cols)\n",
    "    \n",
    "    for idx, img_id in enumerate(img_ids):\n",
    "        img_path = f'{data_path}/images/{img_id}.jpg'\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax = plt.subplot(grid[idx])\n",
    "        ax.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:53.284582Z",
     "iopub.status.busy": "2022-08-29T21:21:53.284202Z",
     "iopub.status.idle": "2022-08-29T21:21:53.294159Z",
     "shell.execute_reply": "2022-08-29T21:21:53.293115Z",
     "shell.execute_reply.started": "2022-08-29T21:21:53.284544Z"
    }
   },
   "outputs": [],
   "source": [
    "num_of_imgs=6\n",
    "last_healthy_img_ids = healthy['image_id'][-num_of_imgs:]\n",
    "last_multiple_diseases_img_ids = multiple_diseases['image_id'][-num_of_imgs:]\n",
    "last_rust_img_ids = rust['image_id'][-num_of_imgs:]\n",
    "last_scab_img_ids = scab['image_id'][-num_of_imgs:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:53.296544Z",
     "iopub.status.busy": "2022-08-29T21:21:53.295846Z",
     "iopub.status.idle": "2022-08-29T21:21:56.83057Z",
     "shell.execute_reply": "2022-08-29T21:21:56.829614Z",
     "shell.execute_reply.started": "2022-08-29T21:21:53.296501Z"
    }
   },
   "outputs": [],
   "source": [
    "show_image(last_healthy_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:21:56.83798Z",
     "iopub.status.busy": "2022-08-29T21:21:56.831878Z",
     "iopub.status.idle": "2022-08-29T21:22:00.891163Z",
     "shell.execute_reply": "2022-08-29T21:22:00.890234Z",
     "shell.execute_reply.started": "2022-08-29T21:21:56.83794Z"
    }
   },
   "outputs": [],
   "source": [
    "show_image(last_multiple_diseases_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:00.893272Z",
     "iopub.status.busy": "2022-08-29T21:22:00.89238Z",
     "iopub.status.idle": "2022-08-29T21:22:04.71849Z",
     "shell.execute_reply": "2022-08-29T21:22:04.717663Z",
     "shell.execute_reply.started": "2022-08-29T21:22:00.893235Z"
    }
   },
   "outputs": [],
   "source": [
    "show_image(last_rust_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:04.720518Z",
     "iopub.status.busy": "2022-08-29T21:22:04.719709Z",
     "iopub.status.idle": "2022-08-29T21:22:08.663223Z",
     "shell.execute_reply": "2022-08-29T21:22:08.662211Z",
     "shell.execute_reply.started": "2022-08-29T21:22:04.720467Z"
    }
   },
   "outputs": [],
   "source": [
    "show_image(last_scab_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:08.665824Z",
     "iopub.status.busy": "2022-08-29T21:22:08.664736Z",
     "iopub.status.idle": "2022-08-29T21:22:13.351212Z",
     "shell.execute_reply": "2022-08-29T21:22:13.347081Z",
     "shell.execute_reply.started": "2022-08-29T21:22:08.665772Z"
    }
   },
   "outputs": [],
   "source": [
    "show_image(last_healthy_img_ids, rows=4, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3.1 시드값 고정 및 GPU 장비 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시드값 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:13.353829Z",
     "iopub.status.busy": "2022-08-29T21:22:13.352723Z",
     "iopub.status.idle": "2022-08-29T21:22:13.940674Z",
     "shell.execute_reply": "2022-08-29T21:22:13.939768Z",
     "shell.execute_reply.started": "2022-08-29T21:22:13.353791Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark=False\n",
    "torch.backends.cudnn.enabled=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU 장비 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:13.942872Z",
     "iopub.status.busy": "2022-08-29T21:22:13.942081Z",
     "iopub.status.idle": "2022-08-29T21:22:14.008408Z",
     "shell.execute_reply": "2022-08-29T21:22:14.007444Z",
     "shell.execute_reply.started": "2022-08-29T21:22:13.942834Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3.2 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:14.01077Z",
     "iopub.status.busy": "2022-08-29T21:22:14.010104Z",
     "iopub.status.idle": "2022-08-29T21:22:14.032586Z",
     "shell.execute_reply": "2022-08-29T21:22:14.031742Z",
     "shell.execute_reply.started": "2022-08-29T21:22:14.010733Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = './input/plant-pathology-2020-fgvc7/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv')\n",
    "test = pd.read_csv(data_path + 'test.csv')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터, 검증 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:14.035877Z",
     "iopub.status.busy": "2022-08-29T21:22:14.035602Z",
     "iopub.status.idle": "2022-08-29T21:22:14.555883Z",
     "shell.execute_reply": "2022-08-29T21:22:14.554919Z",
     "shell.execute_reply.started": "2022-08-29T21:22:14.035852Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, valid = train_test_split(train, test_size=0.2,\n",
    "                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:14.557697Z",
     "iopub.status.busy": "2022-08-29T21:22:14.557248Z",
     "iopub.status.idle": "2022-08-29T21:22:14.567398Z",
     "shell.execute_reply": "2022-08-29T21:22:14.566274Z",
     "shell.execute_reply.started": "2022-08-29T21:22:14.55765Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, img_dir='./', transform=None, is_test=False):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx, 0]\n",
    "        img_path = self.img_dir + img_id + '.jpg'\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)['image']\n",
    "        # 테스트 데이터이면 이미지 데이터만 반환, 그렇지 않으면 타깃값도 반환\n",
    "        if self.is_test:\n",
    "            return image\n",
    "        \n",
    "        else:\n",
    "            # 타깃값 4개 중 가장 큰 값의 인덱스\n",
    "            label = np.argmax(self.df.iloc[idx, 1:5])\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 변환기 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:14.569482Z",
     "iopub.status.busy": "2022-08-29T21:22:14.568922Z",
     "iopub.status.idle": "2022-08-29T21:22:15.60379Z",
     "shell.execute_reply": "2022-08-29T21:22:15.602836Z",
     "shell.execute_reply.started": "2022-08-29T21:22:14.569447Z"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:15.605445Z",
     "iopub.status.busy": "2022-08-29T21:22:15.605107Z",
     "iopub.status.idle": "2022-08-29T21:22:15.615038Z",
     "shell.execute_reply": "2022-08-29T21:22:15.613306Z",
     "shell.execute_reply.started": "2022-08-29T21:22:15.60541Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    #A.Resize(450, 650),\n",
    "    A.Resize(224, 224),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, # 밝기 대비 조절\n",
    "                               contrast_limit=0.2, p=0.3),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.1,\n",
    "        scale_limit=0.2,\n",
    "        rotate_limit=30, p = 0.3),\n",
    "    A.OneOf([A.Emboss(p=1), # 양각화, 날카로움, 블러 효과\n",
    "             A.Sharpen(p=1),\n",
    "             A.Blur(p=1)], p=0.3),\n",
    "    A.PiecewiseAffine(p=0.3), # 어파인 변환\n",
    "    A.Normalize(), # 정규화 변환\n",
    "    ToTensorV2() # 텐서로 변환\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:15.617405Z",
     "iopub.status.busy": "2022-08-29T21:22:15.616376Z",
     "iopub.status.idle": "2022-08-29T21:22:15.626354Z",
     "shell.execute_reply": "2022-08-29T21:22:15.625429Z",
     "shell.execute_reply.started": "2022-08-29T21:22:15.617366Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_test = A.Compose([\n",
    "    #A.Resize(450,650),\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 및 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:15.628081Z",
     "iopub.status.busy": "2022-08-29T21:22:15.627602Z",
     "iopub.status.idle": "2022-08-29T21:22:15.636147Z",
     "shell.execute_reply": "2022-08-29T21:22:15.635049Z",
     "shell.execute_reply.started": "2022-08-29T21:22:15.628046Z"
    }
   },
   "outputs": [],
   "source": [
    "img_dir = './input/plant-pathology-2020-fgvc7/images/'\n",
    "\n",
    "dataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\n",
    "dataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:15.637985Z",
     "iopub.status.busy": "2022-08-29T21:22:15.637563Z",
     "iopub.status.idle": "2022-08-29T21:22:15.65196Z",
     "shell.execute_reply": "2022-08-29T21:22:15.65091Z",
     "shell.execute_reply.started": "2022-08-29T21:22:15.637949Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:15.660227Z",
     "iopub.status.busy": "2022-08-29T21:22:15.659621Z",
     "iopub.status.idle": "2022-08-29T21:22:15.666428Z",
     "shell.execute_reply": "2022-08-29T21:22:15.665519Z",
     "shell.execute_reply.started": "2022-08-29T21:22:15.660199Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainloader = DataLoader(dataset_train, batch_size=batch_size,\n",
    "                          shuffle=True, worker_init_fn = seed_worker,\n",
    "                          generator=g, num_workers=0)\n",
    "validloader = DataLoader(dataset_valid, batch_size=batch_size,\n",
    "                          shuffle=False, worker_init_fn = seed_worker,\n",
    "                          generator=g, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3.3 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:15.670234Z",
     "iopub.status.busy": "2022-08-29T21:22:15.668794Z",
     "iopub.status.idle": "2022-08-29T21:22:28.44206Z",
     "shell.execute_reply": "2022-08-29T21:22:28.440834Z",
     "shell.execute_reply.started": "2022-08-29T21:22:15.670191Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install efficientnet-pytorch==0.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:28.444336Z",
     "iopub.status.busy": "2022-08-29T21:22:28.443905Z",
     "iopub.status.idle": "2022-08-29T21:22:28.457327Z",
     "shell.execute_reply": "2022-08-29T21:22:28.456335Z",
     "shell.execute_reply.started": "2022-08-29T21:22:28.444292Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:28.460213Z",
     "iopub.status.busy": "2022-08-29T21:22:28.459076Z",
     "iopub.status.idle": "2022-08-29T21:22:51.984733Z",
     "shell.execute_reply": "2022-08-29T21:22:51.983726Z",
     "shell.execute_reply.started": "2022-08-29T21:22:28.460176Z"
    }
   },
   "outputs": [],
   "source": [
    "# 사전 훈련된 efficient-b7 모델 불러오기\n",
    "model = EfficientNet.from_pretrained('efficientnet-b4', num_classes=4)\n",
    "\n",
    "model = model.to(device) # 장비 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:51.98676Z",
     "iopub.status.busy": "2022-08-29T21:22:51.986351Z",
     "iopub.status.idle": "2022-08-29T21:22:51.995873Z",
     "shell.execute_reply": "2022-08-29T21:22:51.992752Z",
     "shell.execute_reply.started": "2022-08-29T21:22:51.986707Z"
    }
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:51.998224Z",
     "iopub.status.busy": "2022-08-29T21:22:51.997248Z",
     "iopub.status.idle": "2022-08-29T21:22:52.00343Z",
     "shell.execute_reply": "2022-08-29T21:22:52.002462Z",
     "shell.execute_reply.started": "2022-08-29T21:22:51.998179Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# # 사전 훈련된 efficient-b7 모델 불러오기\n",
    "# model = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "\n",
    "# # 불러온 efficientnet-b7 모델의 마지막 계층 수정\n",
    "# model._fc = nn.Sequential(\n",
    "#                 nn.Linear(model._fc.in_features, model._fc.out_features), # 2560 --> 1000\n",
    "#                 nn.ReLU(), # 활성화함수\n",
    "#                 nn.Dropout(p=0.5), # 50% 드롭아웃\n",
    "#                 nn.Linear(model._fc.out_features, 4) # 1000 --> 4\n",
    "# )\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3.4 모델 훈련 및 성능 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 함수와 옵티마이저 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:52.00574Z",
     "iopub.status.busy": "2022-08-29T21:22:52.004767Z",
     "iopub.status.idle": "2022-08-29T21:22:52.01386Z",
     "shell.execute_reply": "2022-08-29T21:22:52.012915Z",
     "shell.execute_reply.started": "2022-08-29T21:22:52.00569Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim # 옵티마이저 (경사하강법...)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:22:52.015932Z",
     "iopub.status.busy": "2022-08-29T21:22:52.015265Z",
     "iopub.status.idle": "2022-08-29T21:22:52.026896Z",
     "shell.execute_reply": "2022-08-29T21:22:52.025884Z",
     "shell.execute_reply.started": "2022-08-29T21:22:52.015848Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=7, factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 및 성능 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validloader, criterion):\n",
    "    # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비\n",
    "    # 이 최종 예측과 정답을 비교\n",
    "    # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산\n",
    "    num_classes = 4\n",
    "    valid_accuracy = 0\n",
    "    valid_loss = 0\n",
    "    preds_auc_list = [] # 예측 확률값 저장용 리스트 초기화\n",
    "    preds_acc_list = []\n",
    "    true_list = [] # 실제 타깃값 저장용 리스트 초기화\n",
    "    true_onehot_list = []\n",
    "    \n",
    "    # 전방향 예측을 구할 때는 gradient가 필요가 없음\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validloader: # 10000개의 데이터에 대해 100개씩(미니배치 사이즈) 100번을 iterations\n",
    "            # 1. 입력데이터 준비\n",
    "            #images.resize_(images.size()[0], 784) # 100, 1, 28, 28\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 2. 전방향(Forward) 예측 \n",
    "            # logits = model.forward(images) # 점수 반환\n",
    "            outputs = model(images)\n",
    "            # _, preds = torch.max(logits, 1) # 100개에 대한 최종 예측\n",
    "            \n",
    "            loss = criterion(outputs, labels) # 100개에 대한 loss\n",
    "            \n",
    "            # acc 스코어\n",
    "            preds_acc = torch.max(outputs.cpu(), dim=1)[1].numpy()\n",
    "            true = labels.cpu().numpy()\n",
    "            \n",
    "            # roc_auc 스코어\n",
    "            preds_auc = torch.softmax(outputs.cpu(), dim=1).numpy()\n",
    "            true_onehot = torch.eye(num_classes, device='cuda')[labels].cuda().cpu().numpy()\n",
    "            \n",
    "            # ACC와 AUC 스코어 필요 인자가 달라서 각자 계산\n",
    "            # 왜 이렇게 계산하는지 학습 필요\n",
    "            preds_acc_list.extend(preds_acc)\n",
    "            preds_auc_list.extend(preds_auc)\n",
    "            true_list.extend(true)\n",
    "            true_onehot_list.extend(true_onehot)\n",
    "            \n",
    "            # valid_accuracy += accuracy\n",
    "            valid_loss += loss.item() # tensor 값을 꺼내옴 \n",
    "            \n",
    "    valid_auc = roc_auc_score(true_onehot_list, preds_auc_list)\n",
    "    vallid_accuracy = accuracy_score(true_list, preds_acc_list)\n",
    "    return valid_loss, valid_auc, vallid_accuracy # 100세트 전체 대한 총 loss, 총 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm # 진행률 표시 막대\n",
    "writer  = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "val_auc_list = []\n",
    "val_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, criterion, optimizer):\n",
    "    steps = 0\n",
    "    min_loss = 10000\n",
    "    max_accuracy = 0\n",
    "    trigger = 0\n",
    "    patience = 5 # for Early stopping\n",
    "    num_classes = 4\n",
    "  \n",
    "    steps_per_epoch = len(trainloader) \n",
    "  \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, labels in tqdm(trainloader): # 진행률 막대 표시\n",
    "            steps += 1\n",
    "            # 1. 입력 데이터 준비\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 2. 전방향(Forward) 예측 \n",
    "            outputs = model(images) # 예측\n",
    "            loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환\n",
    "      \n",
    "            # 3. 역방향(Backward) 오차(Gradient) 전파\n",
    "            optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해\n",
    "            loss.backward()\n",
    "      \n",
    "            # 4. 경사하강법으로 모델 파라미터 업데이트\n",
    "            optimizer.step() # W <- W -lr*Gradient\n",
    "      \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "            if (steps % steps_per_epoch) == 0: # step :.... (epoch 마다)\n",
    "                model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정\n",
    "                valid_loss, valid_auc, valid_accuracy = validation(model, validloader, criterion)\n",
    "        \n",
    "                # tensorboad 시각화를 위한 로그 이벤트 등록\n",
    "                writer.add_scalar(\"Loss/train\", train_loss/len(trainloader), epoch)\n",
    "                writer.add_scalar(\"Loss/valid\", valid_loss/len(validloader), epoch)\n",
    "                writer.add_scalars(\"Loss/train and valid\",\n",
    "                                  {'train' : train_loss/len(trainloader),\n",
    "                                  'valid' : valid_loss/len(validloader)}, epoch)\n",
    "                \n",
    "                # writer.add_scalar(\"Valid Accuracy\", valid_accuracy/len(validloader), epoch)\n",
    "                writer.add_scalar(\"Valid AUC\", valid_auc, epoch)\n",
    "                writer.add_scalar(\"Valid ACC\", valid_accuracy, epoch)\n",
    "                \n",
    "                train_loss_list.append(train_loss/len(trainloader))\n",
    "                valid_loss_list.append(valid_loss/len(validloader))\n",
    "                val_acc_list.append(valid_accuracy)\n",
    "                val_auc_list.append(valid_auc)\n",
    "                \n",
    "                print('Epoch : {}/{}...'.format(epoch+1, epochs),\n",
    "                      'Train Loss : {:.3f} / '.format(train_loss/len(trainloader)),\n",
    "                      'Valid Loss : {:.3f} / '.format(valid_loss/len(validloader)),\n",
    "                      'Valid AUC : {:.3f} / '.format(valid_auc),\n",
    "                      'Valid Accuracy : {:.3f}'.format(valid_accuracy))\n",
    "              \n",
    "                if valid_accuracy > max_accuracy: \n",
    "                    max_accuracy = valid_accuracy\n",
    "                    torch.save(model.state_dict(), 'best_checkpoint_effb7.pth')\n",
    "        \n",
    "                # Early Stopping (조기 종료)\n",
    "                if valid_loss > min_loss:\n",
    "                    trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가\n",
    "                    print('trigger : ', trigger )\n",
    "                    if trigger > patience:\n",
    "                        print('Early Stopping!!!')\n",
    "                        print('Traning step is finished!!')\n",
    "                        writer.flush()  \n",
    "                        return   \n",
    "                else:\n",
    "                    trigger = 0\n",
    "                    min_loss = valid_loss\n",
    "        \n",
    "                train_loss = 0\n",
    "                model.train()\n",
    "                scheduler.step(valid_loss)\n",
    "  \n",
    "    writer.flush()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# img size 320, 512\n",
    "epochs=50\n",
    "train(model, epochs, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "plt.ylim(0,1.5)\n",
    "sns.lineplot(list(range(len(train_loss_list))), train_loss_list)\n",
    "sns.lineplot(list(range(len(valid_loss_list))), valid_loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train','Val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!taskkill /im tensorboard.exe /f\n",
    "!del /q %TMP%\\.tensorboard-info\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3.5 예측 및 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:52:27.941952Z",
     "iopub.status.busy": "2022-08-29T21:52:27.941299Z",
     "iopub.status.idle": "2022-08-29T21:52:27.949652Z",
     "shell.execute_reply": "2022-08-29T21:52:27.948628Z",
     "shell.execute_reply.started": "2022-08-29T21:52:27.941904Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test = ImageDataset(test, img_dir=img_dir, transform=transform_test, is_test=True)\n",
    " \n",
    "testloader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker,\n",
    "                         generator=g, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:52:27.953325Z",
     "iopub.status.busy": "2022-08-29T21:52:27.952674Z",
     "iopub.status.idle": "2022-08-29T21:54:06.023758Z",
     "shell.execute_reply": "2022-08-29T21:54:06.022406Z",
     "shell.execute_reply.started": "2022-08-29T21:52:27.953284Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval() # 모델을 평가 상태로 설정\n",
    "\n",
    "preds = np.zeros((len(test), 4)) # 예측값 저장용 배열초기화\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, images in enumerate(testloader):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 타깃 예측 확률\n",
    "        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n",
    "        preds[i*batch_size:(i+1)*batch_size] += preds_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:54:06.027262Z",
     "iopub.status.busy": "2022-08-29T21:54:06.025701Z",
     "iopub.status.idle": "2022-08-29T21:54:06.050861Z",
     "shell.execute_reply": "2022-08-29T21:54:06.050004Z",
     "shell.execute_reply.started": "2022-08-29T21:54:06.027216Z"
    }
   },
   "outputs": [],
   "source": [
    "submission[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 성능 개선\n",
    "1. 에폭 늘리기\n",
    "2. 스케줄러 추가\n",
    "3. TTA(테스트 단계 데이터 증강) 기법\n",
    "4. 레이블 스무딩 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4.1 모델 훈련 및 성능 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케줄러 변경 및 에폭증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T21:54:06.052755Z",
     "iopub.status.busy": "2022-08-29T21:54:06.052388Z",
     "iopub.status.idle": "2022-08-29T21:54:10.758511Z",
     "shell.execute_reply": "2022-08-29T21:54:10.75754Z",
     "shell.execute_reply.started": "2022-08-29T21:54:06.052705Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "epochs = 20\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = len(trainloader) * 3,\n",
    "                                            num_training_steps = len(trainloader) * epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, criterion, optimizer):\n",
    "    steps = 0\n",
    "    min_loss = 10000\n",
    "    max_accuracy = 0\n",
    "    trigger = 0\n",
    "    patience = 5 # for Early stopping\n",
    "    num_classes = 4\n",
    "  \n",
    "    steps_per_epoch = len(trainloader) \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, labels in tqdm(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비\n",
    "            steps += 1\n",
    "            # 1. 입력 데이터 준비\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 2. 전방향(Forward) 예측 \n",
    "            outputs = model(images) # 예측\n",
    "            loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환\n",
    "      \n",
    "            # 3. 역방향(Backward) 오차(Gradient) 전파\n",
    "            optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해\n",
    "            loss.backward()\n",
    "      \n",
    "            # 4. 경사하강법으로 모델 파라미터 업데이트\n",
    "            optimizer.step() # W <- W -lr*Gradient\n",
    "      \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "            if (steps % steps_per_epoch) == 0: # step : 3125, .... (epoch 마다)\n",
    "                model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정\n",
    "                valid_loss, valid_auc, valid_accuracy = validation(model, validloader, criterion)\n",
    "        \n",
    "                # tensorboad 시각화를 위한 로그 이벤트 등록\n",
    "                writer.add_scalar(\"Loss/train\", train_loss/len(trainloader), epoch)\n",
    "                writer.add_scalar(\"Loss/valid\", valid_loss/len(validloader), epoch)\n",
    "                writer.add_scalars(\"Loss/train and valid\",\n",
    "                                  {'train' : train_loss/len(trainloader),\n",
    "                                  'valid' : valid_loss/len(validloader)}, epoch)\n",
    "                \n",
    "                # writer.add_scalar(\"Valid Accuracy\", valid_accuracy/len(validloader), epoch)\n",
    "                writer.add_scalar(\"Valid AUC\", valid_auc, epoch)\n",
    "        \n",
    "                print('Epoch : {}/{}.....'.format(epoch+1, epochs),\n",
    "                      'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),\n",
    "                      'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),\n",
    "                      'Valid AUC : {:.3f}'.format(valid_auc),\n",
    "                      'Valid Accuracy : {:.3f}'.format(valid_accuracy))\n",
    "              \n",
    "                if valid_auc > max_accuracy: \n",
    "                    max_accuracy = valid_auc\n",
    "                    torch.save(model.state_dict(), 'best_checkpoint.pth')\n",
    "        \n",
    "                # Early Stopping (조기 종료)\n",
    "                if valid_loss > min_loss:\n",
    "                    trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가\n",
    "                    print('trigger : ', trigger )\n",
    "                    if trigger > patience:\n",
    "                        print('Early Stopping!!!')\n",
    "                        print('Traning step is finished!!')\n",
    "                        writer.flush()  \n",
    "                        return   \n",
    "                else:\n",
    "                    trigger = 0\n",
    "                    min_loss = valid_loss\n",
    "        \n",
    "                train_loss = 0\n",
    "                model.train()\n",
    "                scheduler.step()\n",
    "  \n",
    "    writer.flush()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 및 성능 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "train(model, epochs, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T05:19:17.302701Z",
     "iopub.status.busy": "2022-08-30T05:19:17.302386Z",
     "iopub.status.idle": "2022-08-30T05:19:17.383857Z",
     "shell.execute_reply": "2022-08-30T05:19:17.38183Z",
     "shell.execute_reply.started": "2022-08-30T05:19:17.302637Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test = ImageDataset(test, img_dir=img_dir, transform=transform_test, is_test=True)\n",
    "\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g, num_workers=0)\n",
    "\n",
    "dataset_TTA = ImageDataset(test, img_dir=img_dir, transform=transform_train, is_test=True)\n",
    "\n",
    "loader_TTA = DataLoader(dataset_TTA, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 데이터 원본으로 예측한 타깃값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-30T05:19:17.384768Z",
     "iopub.status.idle": "2022-08-30T05:19:17.385125Z",
     "shell.execute_reply": "2022-08-30T05:19:17.384971Z",
     "shell.execute_reply.started": "2022-08-30T05:19:17.384953Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "preds_test = np.zeros((len(test), 4))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, images in enumerate(testloader):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 타깃 예측 확률\n",
    "        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n",
    "        preds_test[i*batch_size:(i+1)*batch_size] += preds_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T05:19:17.423522Z",
     "iopub.status.busy": "2022-08-30T05:19:17.422905Z",
     "iopub.status.idle": "2022-08-30T05:19:17.439Z",
     "shell.execute_reply": "2022-08-30T05:19:17.437629Z",
     "shell.execute_reply.started": "2022-08-30T05:19:17.423486Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "threshold = 0.999\n",
    "\n",
    "submission_test_ls = submission_test.copy()\n",
    "submission_tta_ls = submission_tta.copy()\n",
    "\n",
    "target = ['healthy', 'multiple_diseases', 'rust', 'scab']\n",
    "\n",
    "submission_test_ls[target] = apply_label_smoothing(submission_test_ls, target, alpha, threshold)\n",
    "\n",
    "submission_tta_ls[target] = apply_label_smoothing(submission_tta_ls, target, alpha, threshold)\n",
    "\n",
    "submission_test_ls.to_csv('submission_test_ls.csv', index=False)\n",
    "submission_tta_ls.to_csv('submission_tta_ls.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
