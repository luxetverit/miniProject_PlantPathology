{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-12T02:59:02.567292Z","iopub.execute_input":"2023-01-12T02:59:02.567639Z","iopub.status.idle":"2023-01-12T02:59:05.702112Z","shell.execute_reply.started":"2023-01-12T02:59:02.567562Z","shell.execute_reply":"2023-01-12T02:59:05.700937Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# 시드값 고정\nseed = 42\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:05.704261Z","iopub.execute_input":"2023-01-12T02:59:05.705073Z","iopub.status.idle":"2023-01-12T02:59:05.716043Z","shell.execute_reply.started":"2023-01-12T02:59:05.705031Z","shell.execute_reply":"2023-01-12T02:59:05.714995Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:05.717511Z","iopub.execute_input":"2023-01-12T02:59:05.718122Z","iopub.status.idle":"2023-01-12T02:59:05.878859Z","shell.execute_reply.started":"2023-01-12T02:59:05.718084Z","shell.execute_reply":"2023-01-12T02:59:05.877492Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')\nfrom sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(train, \n                                test_size=0.1,\n                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n                                random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:05.884683Z","iopub.execute_input":"2023-01-12T02:59:05.887124Z","iopub.status.idle":"2023-01-12T02:59:06.192559Z","shell.execute_reply.started":"2023-01-12T02:59:05.887076Z","shell.execute_reply":"2023-01-12T02:59:06.188186Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\nimport numpy as np\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None, is_test=False):\n        super().__init__() # 상속받은 Dataset의 __init__() 메서드 호출\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n\n    # 인덱스(idx)에 해당하는 데이터 반환 메서드\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]             # 이미지 ID\n        img_path = self.img_dir + img_id + '.jpg' # 이미지 파일 경로\n        image = cv2.imread(img_path)              # 이미지 파일 읽기\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        # 이미지 변환 \n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        # 테스트 데이터면 이미지 데이터만 반환, 그렇지 않으면 타깃값도 반환 \n        if self.is_test:\n            return image # 테스트용일 때\n        else:\n            # 타깃값 4개 중 가장 큰 값의 인덱스 \n            label = np.argmax(self.df.iloc[idx, 1:5]) \n            return image, label # 훈련/검증용일 때","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:06.197064Z","iopub.execute_input":"2023-01-12T02:59:06.200184Z","iopub.status.idle":"2023-01-12T02:59:06.448513Z","shell.execute_reply.started":"2023-01-12T02:59:06.200128Z","shell.execute_reply":"2023-01-12T02:59:06.447293Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 이미지 변환을 위한 모듈\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:06.454078Z","iopub.execute_input":"2023-01-12T02:59:06.456960Z","iopub.status.idle":"2023-01-12T02:59:07.977006Z","shell.execute_reply.started":"2023-01-12T02:59:06.456915Z","shell.execute_reply":"2023-01-12T02:59:07.975977Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 훈련 데이터용 변환기\ntransform_train = A.Compose([\n    A.Resize(450, 650),       # 이미지 크기 조절 \n    A.RandomBrightnessContrast(brightness_limit=0.2, # 밝기 대비 조절\n                               contrast_limit=0.2, p=0.3),\n    A.VerticalFlip(p=0.2),    # 상하 대칭 변환\n    A.HorizontalFlip(p=0.5),  # 좌우 대칭 변환 \n    A.ShiftScaleRotate(       # 이동, 스케일링, 회전 변환\n        shift_limit=0.1,\n        scale_limit=0.2,\n        rotate_limit=30, p=0.3),\n    A.OneOf([A.Emboss(p=1),   # 양각화, 날카로움, 블러 효과\n             A.Sharpen(p=1),\n             A.Blur(p=1)], p=0.3),\n    A.PiecewiseAffine(p=0.3), # 어파인 변환 \n    A.Normalize(),            # 정규화 변환 \n    ToTensorV2()              # 텐서로 변환\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:07.980448Z","iopub.execute_input":"2023-01-12T02:59:07.980803Z","iopub.status.idle":"2023-01-12T02:59:07.991208Z","shell.execute_reply.started":"2023-01-12T02:59:07.980774Z","shell.execute_reply":"2023-01-12T02:59:07.990141Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 검증 및 테스트 데이터용 변환기\ntransform_test = A.Compose([\n    A.Resize(450, 650), # 이미지 크기 조절 \n    A.Normalize(),      # 정규화 변환\n    ToTensorV2()        # 텐서로 변환\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:07.993135Z","iopub.execute_input":"2023-01-12T02:59:07.993599Z","iopub.status.idle":"2023-01-12T02:59:08.005812Z","shell.execute_reply.started":"2023-01-12T02:59:07.993559Z","shell.execute_reply":"2023-01-12T02:59:08.004536Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\ndataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:08.007636Z","iopub.execute_input":"2023-01-12T02:59:08.008206Z","iopub.status.idle":"2023-01-12T02:59:08.018115Z","shell.execute_reply.started":"2023-01-12T02:59:08.008168Z","shell.execute_reply":"2023-01-12T02:59:08.016218Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:08.032359Z","iopub.execute_input":"2023-01-12T02:59:08.032730Z","iopub.status.idle":"2023-01-12T02:59:08.051660Z","shell.execute_reply.started":"2023-01-12T02:59:08.032693Z","shell.execute_reply":"2023-01-12T02:59:08.048520Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f075fbaaed0>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 클래스\n\nbatch_size = 4\n\ntrainloader = DataLoader(dataset_train, batch_size=batch_size, \n                          shuffle=True, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)\nvalidloader = DataLoader(dataset_valid, batch_size=batch_size, \n                          shuffle=False, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:08.053408Z","iopub.execute_input":"2023-01-12T02:59:08.055067Z","iopub.status.idle":"2023-01-12T02:59:08.063725Z","shell.execute_reply.started":"2023-01-12T02:59:08.055029Z","shell.execute_reply":"2023-01-12T02:59:08.062633Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1\nfrom efficientnet_pytorch import EfficientNet # EfficientNet 모델\n# 사전 훈련된 efficientnet-b7 모델 불러오기\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4) \n\nmodel = model.to(device) # 장비 할당","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:08.065667Z","iopub.execute_input":"2023-01-12T02:59:08.066183Z","iopub.status.idle":"2023-01-12T02:59:32.883860Z","shell.execute_reply.started":"2023-01-12T02:59:08.066147Z","shell.execute_reply":"2023-01-12T02:59:32.882818Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Collecting efficientnet-pytorch==0.7.1\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.7.1) (1.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1) (4.1.1)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=4ad2699be0275e07618b737be6d3a17ad967edc977cfc9a76e14bb3843a9ec32\n  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/254M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e65a68d6a9248e48d3d7285ae5e98e0"}},"metadata":{}},{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b7\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\nfrom tqdm import tqdm\n# 손실 함수\ncriterion = nn.CrossEntropyLoss()\n\n# 옵티마이저\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001) # 모델파라미터,러닝레이트, 가중치감쇠\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=7, factor=0.1, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:32.887468Z","iopub.execute_input":"2023-01-12T02:59:32.887836Z","iopub.status.idle":"2023-01-12T02:59:32.898654Z","shell.execute_reply.started":"2023-01-12T02:59:32.887803Z","shell.execute_reply":"2023-01-12T02:59:32.897563Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def validation(model, validloader, criterion):\n  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비\n  # 이 최종 예측과 정답을 비교\n  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산\n  valid_accuracy = 0\n  valid_loss = 0\n\n  # 전방향 예측을 구할 때는 gradient가 필요가 없음\n  with torch.no_grad():\n    for images, labels in validloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) 10000/16번을 iterations\n      # 0. Data를 GPU로 보내기\n      images, labels = images.to(device), labels.to(device)\n\n      # 1. 입력데이터 준비\n      # not Flatten!!\n      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28\n      \n      # 2. 전방향(Forward) 예측 \n      logits = model.forward(images) # 점수 반환\n      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측\n      # preds= probs.max(dim=1)[1] \n      correct = (preds == labels).sum()\n\n      accuracy = correct / images.shape[0]\n      loss = criterion(logits, labels) # 16개에 대한 loss\n      \n      valid_accuracy += accuracy\n      valid_loss += loss.item() # tensor 값을 꺼내옴\n    \n\n  return valid_loss, valid_accuracy # validloader 전체 대한 총 loss, 총 accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:32.900197Z","iopub.execute_input":"2023-01-12T02:59:32.900576Z","iopub.status.idle":"2023-01-12T02:59:32.912245Z","shell.execute_reply.started":"2023-01-12T02:59:32.900540Z","shell.execute_reply":"2023-01-12T02:59:32.911049Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\n\nwriter  = SummaryWriter()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:32.913710Z","iopub.execute_input":"2023-01-12T02:59:32.914198Z","iopub.status.idle":"2023-01-12T02:59:37.925043Z","shell.execute_reply.started":"2023-01-12T02:59:32.914163Z","shell.execute_reply":"2023-01-12T02:59:37.923875Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, epochs, criterion, optimizer):\n  train_loss = []\n  valid_loss = []\n  train_acc = []\n  val_acc = []\n  steps = 0\n  min_loss = 10000\n  max_accuracy = 0\n\n  trigger = 0\n  patience = 5 # for Early stopping\n\n  # 1 에폭(epoch)당 반복수\n  #steps_per_epoch = len(trainset)/batch_size # 2500 iterations\n  steps_per_epoch = len(trainloader) # 2500 iterations\n\n  for epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    for images, labels in tqdm(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비\n      steps += 1\n      # 0. Data를 GPU로 보내기\n      images, labels = images.to(device), labels.to(device)\n\n      # 1. 입력 데이터 준비\n      # not Flatten!!\n      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28\n\n      # 2. 전방향(Forward) 예측 \n      outputs = model.forward(images) # 예측\n      loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환\n\n      # 3. 역방향(Backward) 오차(Gradient) 전파\n      optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해\n      loss.backward()\n\n      # 4. 경사하강법으로 모델 파라미터 업데이트\n      optimizer.step() # W <- W -lr*Gradient\n\n      train_loss += loss.item()\n      if (steps % steps_per_epoch) == 0: # step : 2500, .... (epoch 마다)\n        model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정\n        valid_loss, valid_accuracy = validation(model, validloader, criterion)\n\n        # tensorboad 시각화를 위한 로그 이벤트 등록\n        writer.add_scalar(\"Loss/train\", train_loss/len(trainloader), epoch)\n        writer.add_scalar(\"Loss/valid\", valid_loss/len(validloader), epoch)\n        writer.add_scalars(\"Loss/train and valid\",\n                          {'train' : train_loss/len(trainloader),\n                          'valid' : valid_loss/len(validloader)}, epoch)\n        \n        writer.add_scalar(\"Valid Accuracy\", valid_accuracy/len(validloader), epoch)\n\n\n        print('Epoch : {}/{}.....'.format(epoch+1, epochs),\n              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),\n              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),\n              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))\n        \n        # Best model 저장\n        # option 1\n        # if valid_loss < min_loss:\n        #   min_loss = valid_loss\n        #   torch.save(model.state_dict(), 'best_checkpoint.pth')\n\n        # option 2\n        if valid_accuracy > max_accuracy: \n          max_accuracy = valid_accuracy\n          torch.save(model.state_dict(), 'best_checkpoint.pth')\n\n        # Early Stopping (조기 종료)\n        if valid_loss > min_loss:\n          trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가\n          print('trigger : ', trigger )\n          if trigger > patience:\n            print('Early Stopping!!!')\n            print('Traning step is finished!!')\n            writer.flush()  \n            return   \n        else:\n          trigger = 0\n          min_loss = valid_loss\n\n\n        train_loss = 0\n        model.train()\n\n        # Learning Rate Scheduler\n        scheduler.step(valid_loss)\n  plt.figure()\n  plt.ylim(0,1.5)\n  sns.lineplot(list(range(len(train_loss))), train_loss)\n  sns.lineplot(list(range(len(valid_loss))), valid_loss)\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.legend(['Train','Val'])\n  writer.flush()      ","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:37.926905Z","iopub.execute_input":"2023-01-12T02:59:37.927382Z","iopub.status.idle":"2023-01-12T02:59:37.944001Z","shell.execute_reply.started":"2023-01-12T02:59:37.927339Z","shell.execute_reply":"2023-01-12T02:59:37.942856Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"epochs=20\ntrain(model, epochs, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T02:59:37.945686Z","iopub.execute_input":"2023-01-12T02:59:37.946353Z","iopub.status.idle":"2023-01-12T04:53:06.828556Z","shell.execute_reply.started":"2023-01-12T02:59:37.946314Z","shell.execute_reply":"2023-01-12T04:53:06.827202Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|█████████▉| 409/410 [07:51<00:01,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch : 1/20..... Train Loss : 0.670 Valid Loss : 0.207 Valid Accuracy : 0.929\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:07<00:00,  1.19s/it]\n100%|█████████▉| 409/410 [07:51<00:01,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch : 2/20..... Train Loss : 0.368 Valid Loss : 0.204 Valid Accuracy : 0.962\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:06<00:00,  1.19s/it]\n100%|██████████| 410/410 [08:05<00:00,  1.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 3/20..... Train Loss : 0.272 Valid Loss : 0.181 Valid Accuracy : 0.935\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:04<00:00,  1.18s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 4/20..... Train Loss : 0.202 Valid Loss : 0.188 Valid Accuracy : 0.946\ntrigger :  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:03<00:00,  1.18s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 5/20..... Train Loss : 0.149 Valid Loss : 0.254 Valid Accuracy : 0.940\ntrigger :  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:07<00:00,  1.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 6/20..... Train Loss : 0.119 Valid Loss : 0.242 Valid Accuracy : 0.946\ntrigger :  3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:05<00:00,  1.18s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 7/20..... Train Loss : 0.111 Valid Loss : 0.242 Valid Accuracy : 0.940\ntrigger :  4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:04<00:00,  1.18s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 8/20..... Train Loss : 0.094 Valid Loss : 0.158 Valid Accuracy : 0.962\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:07<00:00,  1.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 9/20..... Train Loss : 0.083 Valid Loss : 0.244 Valid Accuracy : 0.951\ntrigger :  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:08<00:00,  1.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 10/20..... Train Loss : 0.057 Valid Loss : 0.316 Valid Accuracy : 0.918\ntrigger :  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:06<00:00,  1.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 11/20..... Train Loss : 0.061 Valid Loss : 0.204 Valid Accuracy : 0.951\ntrigger :  3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:05<00:00,  1.18s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 12/20..... Train Loss : 0.049 Valid Loss : 0.341 Valid Accuracy : 0.924\ntrigger :  4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 410/410 [08:06<00:00,  1.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 13/20..... Train Loss : 0.054 Valid Loss : 0.282 Valid Accuracy : 0.935\ntrigger :  5\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 409/410 [07:52<00:01,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch : 14/20..... Train Loss : 0.043 Valid Loss : 0.202 Valid Accuracy : 0.967\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 409/410 [08:08<00:01,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"trigger :  6\nEarly Stopping!!!\nTraning step is finished!!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test = ImageDataset(test, img_dir=img_dir, \n                            transform=transform_test, is_test=True)\nloader_test = DataLoader(dataset_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)\n\n# TTA용 데이터셋 및 데이터 로더\ndataset_TTA = ImageDataset(test, img_dir=img_dir, \n                           transform=transform_train, is_test=True)\nloader_TTA = DataLoader(dataset_TTA, batch_size=batch_size, \n                        shuffle=False, worker_init_fn=seed_worker,\n                        generator=g, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T05:12:18.914929Z","iopub.execute_input":"2023-01-12T05:12:18.915325Z","iopub.status.idle":"2023-01-12T05:12:18.922218Z","shell.execute_reply.started":"2023-01-12T05:12:18.915292Z","shell.execute_reply":"2023-01-12T05:12:18.920983Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.eval() # 모델을 평가 상태로 설정 \n\npreds_test = np.zeros((len(test), 4)) # 예측값 저장용 배열 초기화\n\nwith torch.no_grad():\n    for i, images in enumerate(loader_test):\n        images = images.to(device)\n        outputs = model(images)\n        # 타깃 예측 확률\n        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n        preds_test[i*batch_size:(i+1)*batch_size] += preds_part\nsubmission_test = submission.copy() # 제출 샘플 파일 복사\n\nsubmission_test[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_test","metadata":{"execution":{"iopub.status.busy":"2023-01-12T05:12:20.822693Z","iopub.execute_input":"2023-01-12T05:12:20.823084Z","iopub.status.idle":"2023-01-12T05:14:36.109892Z","shell.execute_reply.started":"2023-01-12T05:12:20.823053Z","shell.execute_reply":"2023-01-12T05:14:36.108581Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"submission_test.to_csv('submission_test.csv', index=False)\n# submission_tta.to_csv('submission_tta.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T05:15:50.000287Z","iopub.execute_input":"2023-01-12T05:15:50.000668Z","iopub.status.idle":"2023-01-12T05:15:50.020783Z","shell.execute_reply.started":"2023-01-12T05:15:50.000637Z","shell.execute_reply":"2023-01-12T05:15:50.019857Z"},"trusted":true},"execution_count":28,"outputs":[]}]}